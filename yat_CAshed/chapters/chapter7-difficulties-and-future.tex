% 第七章：困难、解决方案与未来展望
\section{困难、解决方案与未来展望} \label{sec:difficulties_future}

\subsection{项目挑战与应对策略}

在项目的推进过程中，我们不仅面临了技术实现上的重重关卡，也遇到了项目管理与团队协作方面的挑战。本节将对这些困难进行梳理，并阐述我们的应对策略。

\subsubsection{项目管理挑战}

\begin{itemize}
    \item \textbf{时间资源紧张与多重压力并行}：作为大二学生，团队成员普遍面临着繁重的课内学业压力。同时，部分成员还需要投入时间准备保研等个人发展事宜，导致能够投入到项目开发的时间相对有限且碎片化。
  
    \textbf{应对策略}：我们通过制定详细的周度计划，明确每个阶段的核心任务和分工，利用课余时间高效开发。在期末考试结束后，团队将利用暑假进行集中攻关，以弥补之前有限的开发时间。

    \item \textbf{Linux内核开发学习资源匮乏}：与应用层开发不同，Linux内核调度器的开发缺乏系统性的、零基础的中文教程。项目初期，我们在理解内核机制和寻找开发入口时遇到了较大的困难，只能依赖零散的英文文档、内核源码和借鉴其他开源调度器项目，摸索前行。
   
    \textbf{应对策略}：团队成员分工合作，系统性地阅读了《Linux内核设计与实现》等经典书籍，并深入分析了CFS、FIFO等现有调度器的源码。
\end{itemize}

\subsubsection{技术实现挑战与解决方案}

\paragraph{理论研究与环境搭建的挑战}

在项目初期，我们面临两大技术难题：一是现代处理器复杂的缓存行为难以精确建模；二是为内核开发搭建稳定高效的QEMU多核测试环境时，遇到了虚拟CPU性能异常和串口输出冲突等问题。

\textbf{我们的对策是}：对缓存行为采用简化的启发式模型，规避复杂数学建模的困难；同时，通过标准化QEMU启动参数和统一调试输出通道，解决了环境配置的障碍。

\paragraph{内核数据结构设计的重大挑战}

项目中期，我们在设计核心数据结构时遇到了严重的技术障碍。最初设计的全局就绪池方案存在严重的可扩展性问题，在多核环境下会导致严重的锁竞争和性能瓶颈。

\textbf{具体问题表现}：
\begin{itemize}
    \item[×] 全局锁竞争导致多核调度性能严重下降
    \item[×] 复杂的缓存benefit计算在调度热点路径中引入过大开销  
    \item[×] 动态内存分配在中断上下文中可能导致系统不稳定
\end{itemize}

\textbf{解决方案的演进}：
\begin{itemize}
    \item[✓] \textbf{架构重构}：放弃全局就绪池，改用每CPU独立的红黑树运行队列
    \item[✓] \textbf{算法简化}：将复杂的benefit计算简化为基于负载的启发式选择
    \item[✓] \textbf{内存优化}：引入Slab缓存和内存池，避免调度路径中的动态分配
\end{itemize}

\paragraph{红黑树实现的技术难点}

在从理论设计转向实际编码时，红黑树的正确实现成为了关键瓶颈。

\textbf{遇到的核心问题}：
\begin{lstlisting}[language=C, basicstyle=\small\ttfamily]
// 问题1：节点状态未正确清除导致的插入错误
RB_CLEAR_NODE(&p->yat_casched.rb_node); // 关键修复

// 问题2：容器类型转换的层次错误
se_entry = rb_entry(parent, struct sched_yat_casched_entity, rb_node);
task_entry = container_of(se_entry, struct task_struct, yat_casched);

// 问题3：缓存节点更新的时机控制
rb_insert_color_cached(&p->yat_casched.rb_node, &yat_rq->tasks, leftmost);
\end{lstlisting}

这些看似细微的实现细节，却导致了系统启动时的内核崩溃和调度异常。我们通过大量的代码审查和调试，逐一解决了这些问题。

\paragraph{时间片与抢占机制的实现挑战}

实现合理的时间片轮转和抢占机制时，我们遇到了时机控制的难题：

\textbf{核心技术难点}：
\begin{lstlisting}[language=C, basicstyle=\small\ttfamily]
// 时间片检查的精确实现
if (p->se.sum_exec_runtime - p->se.prev_sum_exec_runtime >= YAT_TIME_SLICE) {
    resched_curr(rq); // 关键：避免立即抢占，而是设置标志
    p->se.prev_sum_exec_runtime = p->se.sum_exec_runtime;
}

// 空闲任务抢占的关键修复  
if (is_idle_task(rq->curr)) {
    resched_curr(rq); // 必须立即抢占空闲任务
}
\end{lstlisting}

最终通过精确的时间戳管理和抢占标志控制，实现了稳定的时间片轮转机制。

\paragraph{内核集成与系统调用接口的挑战}

将调度器正确集成到内核编译系统并提供用户态接口时，我们遇到了配置系统的复杂性：

\textbf{解决的关键问题}：
\begin{itemize}
    \item[△] \textbf{编译依赖处理}：通过条件编译宏确保在不同内核配置下的兼容性
    \item[△] \textbf{头文件导出}：正确配置\texttt{include/uapi}使用户态能访问调度策略常量  
    \item[△] \textbf{自动化脚本}：开发一键配置脚本，解决复杂的内核选项设置问题
\end{itemize}

\paragraph{调试与验证的复合挑战}

项目后期的调试过程暴露了多个层面的技术挑战：

\textbf{1. 内核启动崩溃的排查}
\begin{lstlisting}[language=bash, basicstyle=\small\ttfamily]
# 典型的调试过程
[    0.234567] kernel BUG at kernel/sched/yat_casched.c:234!
[    0.234568] invalid opcode: 0000 [#1] SMP PTI
[    0.234569] CPU: 0 PID: 1 Comm: swapper/0 Not tainted 6.8.0-yat+
\end{lstlisting}

通过添加大量的\texttt{printk}调试信息和\texttt{WARN\_ON}断言，我们定位了初始化时序和空指针访问等问题。

\textbf{2. 性能测试结果的不稳定性}
我们发现在QEMU多核环境中，测试结果存在较大波动。通过标准化测试环境、增加预热阶段、多轮测试取平均值等方法，获得了稳定可靠的性能数据。

\textbf{3. Debugfs接口的开发与调试}
实现调试接口时遇到了文件系统挂载时机和权限问题：

\begin{lstlisting}[language=C, basicstyle=\small\ttfamily]
// 延迟初始化解决挂载时机问题
static int __init yat_debugfs_late_init(void)
{
    yat_debugfs_init();
    return 0;
}
late_initcall(yat_debugfs_late_init); // 关键修复
\end{lstlisting}

\paragraph{多层缓存历史表的实现复杂性}

代码中的L1、L2、L3三级缓存历史表实现带来了额外的复杂性：

\textbf{主要技术挑战}：
\begin{itemize}
    \item[※] \textbf{哈希表与链表的双重维护}：需要同时维护基于PID的哈希查找和基于时间的LRU淘汰
    \item[※] \textbf{内存管理的精确控制}：频繁的历史记录分配释放需要避免内存泄漏
    \item[※] \textbf{并发访问的同步保护}：多个CPU同时更新历史表时的竞态条件处理
\end{itemize}

我们通过内存池预分配、读写锁分离、无锁算法优化等技术手段，最终实现了高效稳定的历史表管理。

\paragraph{缓存历史记录机制的设计与优化挑战}

在实现缓存感知调度的核心机制——历史记录表时，我们遇到了设计理念与工程实现之间的重大冲突。

\textbf{初期设计的理想化假设}：
我们最初设计了一个完整的三级缓存历史追踪系统，包含L1、L2、L3三个层次的历史表，每个表都维护着详细的任务执行记录。理论上，这样的设计能够精确地反映任务在不同缓存层次上的热度情况。

\textbf{实际实现中暴露的问题}：
\begin{lstlisting}[language=C, basicstyle=\small\ttfamily, caption={历史记录更新的复杂逻辑}]
// 每次任务切换都需要更新三级缓存历史
void add_history_record(int cpu, struct task_struct *p, u64 exec_time) {
    int l2_cluster_id = cpu / CPU_NUM_PER_SET;
    u64 now = rq_clock_task(cpu_rq(cpu));

    // 分别更新 L1, L2, L3 - 这带来了巨大的开销！
    __update_cache_level(&L1_caches[cpu], p->pid, now, exec_time);
    __update_cache_level(&L2_caches[l2_cluster_id], p->pid, now, exec_time);
    __update_cache_level(&L3_cache, p->pid, now, exec_time);
}
\end{lstlisting}

\textbf{性能测试中发现的严重问题}：
\begin{itemize}
    \item[✗] \textbf{调度开销激增}：每次任务切换需要执行三次哈希查找和链表操作，导致调度延迟显著增加
    \item[✗] \textbf{内存占用失控}：大量的历史记录结构体消耗了过多内存，特别是在高负载场景下
    \item[✗] \textbf{锁竞争问题}：多个CPU同时访问全局L3历史表时产生严重的锁竞争
\end{itemize}

\textbf{务实的简化策略}：
最终，我们在保持核心缓存感知能力的前提下，大幅简化了历史记录机制：
\begin{itemize}
    \item[✓] \textbf{选择性使用}：在CPU选择算法中仅在必要时才进行复杂的历史查询
    \item[✓] \textbf{快速失效机制}：通过时间窗口快速判定缓存失效，避免不必要的历史表访问
    \item[✓] \textbf{简化数据结构}：重点优化最常用的L1缓存历史表，适当简化L2、L3的实现
\end{itemize}

这一经历让我们深刻认识到，在系统级软件开发中，理论上的最优解往往需要在工程实践中做出权衡。

\subsection{未来工作与展望} \label{sec:future}

基于当前Yat-CASched调度器的实现现状和在开发过程中积累的经验，未来的工作将围绕以下核心方向展开，旨在构建一个更加完善、实用的轻量级调度器。

\subsubsection{核心功能完善与优化}

\paragraph{关键任务优先调度机制的完整实现}

当前版本的Yat-CASched虽然在框架设计中预留了关键任务优先的接口，但尚未实现完整的优先级抢占逻辑。这是实现赛题目标"支持对指定数量关键进程的优先调度"的核心功能。

\textbf{具体实现计划}：
\begin{itemize}
    \item[→] \textbf{扩展系统调用接口}：新增 \texttt{sched\_set\_critical()}系统调用，允许用户态程序将指定任务标记为关键任务
    \item[→] \textbf{抢占逻辑实现}：在 \texttt{wakeup\_preempt\_yat\_casched()}中实现关键任务对普通任务的立即抢占
    \item[→] \textbf{公平性保障机制}：设计时间片补偿机制，防止非关键任务长时间得不到调度
\end{itemize}

\begin{lstlisting}[language=C, basicstyle=\small\ttfamily, caption={关键任务抢占逻辑设计}]
void wakeup_preempt_yat_casched(struct rq *rq, struct task_struct *p, int flags)
{
    // 当前实现：仅处理空闲任务抢占
    if (is_idle_task(rq->curr)) {
        resched_curr(rq);
        return;
    }
    
    // 未来实现：关键任务抢占逻辑
    if (p->yat_casched.is_critical && !rq->curr->yat_casched.is_critical) {
        resched_curr(rq); // 关键任务立即抢占普通任务
    }
}
\end{lstlisting}

\paragraph{缓存感知算法的智能化升级}

当前的缓存感知机制相对简化，主要依赖时间窗口判断。未来将引入更精确的缓存热度评估算法。

\textbf{优化方向}：
\begin{itemize}
    \item[◆] \textbf{动态时间窗口}：根据系统负载和硬件特性动态调整缓存热度时间窗口
    \item[◆] \textbf{多级缓存建模}：完善L1、L2、L3三级缓存的历史记录机制，但采用更高效的实现
    \item[◆] \textbf{硬件计数器集成}：利用CPU性能计数器获取真实的缓存命中率数据
\end{itemize}

\paragraph{调度延迟的进一步优化}

针对"极低调度延迟"的目标，计划在以下方面继续优化：

\begin{itemize}
    \item[※] \textbf{无锁数据结构}：探索基于RCU的无锁红黑树实现，减少锁竞争
    \item[※] \textbf{批量操作优化}：在高负载场景下采用批量入队/出队，减少频繁的树操作
    \item[※] \textbf{预测式调度}：基于任务历史行为预测其运行时长，优化时间片分配
\end{itemize}

\subsubsection{场景化适配与扩展}

\paragraph{多场景部署的适配优化}

根据赛题要求的"适用于终端、车载、云等场景"，需要针对不同场景进行专门优化：

\textbf{终端场景优化}：
\begin{itemize}
    \item[△] \textbf{低功耗模式}：与CPU频率调节器(\texttt{cpufreq})联动，在保证响应性的前提下降低功耗
    \item[△] \textbf{交互响应优化}：为GUI应用和用户交互任务提供更高的调度优先级
    \item[△] \textbf{内存占用优化}：进一步减少调度器的内存footprint，适应资源受限的终端设备
\end{itemize}

\textbf{车载场景优化}：
\begin{itemize}
    \item[△] \textbf{实时性保障}：引入deadline感知机制，为安全关键任务提供硬实时保障
    \item[△] \textbf{故障隔离机制}：实现任务组隔离，防止单个应用的异常影响整个系统
    \item[△] \textbf{ARM架构支持}：适配ARM big.LITTLE异构架构，实现核心间的智能迁移
\end{itemize}

\textbf{云计算场景优化}：
\begin{itemize}
    \item[△] \textbf{NUMA感知}：增加对NUMA节点的亲和性支持，减少远程内存访问
    \item[△] \textbf{容器化支持}：与cgroup机制深度集成，支持容器级别的调度策略
    \item[△] \textbf{动态负载均衡}：实现更智能的跨CPU负载均衡算法
\end{itemize}

\subsubsection{工程化与产业化推进}

\paragraph{完善测试与验证体系}

当前的测试主要集中在基本功能验证，需要构建更全面的测试体系：

\textbf{自动化测试框架}：
\begin{lstlisting}[language=bash, basicstyle=\small\ttfamily, caption={自动化测试脚本框架}]
#!/bin/bash
# Yat-CASched 自动化测试套件

# 基准测试
run_hackbench_test() {
    echo "Running hackbench with $1 groups..."
    hackbench -g $1 -l 1000 | grep "Time:"
}

# 延迟测试  
run_latency_test() {
    cyclictest -t 4 -p 99 -n -q -l 10000
}

# 关键任务抢占测试
run_preemption_test() {
    # 测试关键任务是否能够及时抢占普通任务
    ./critical_task_test
}
\end{lstlisting}

\textbf{边界情况测试}：
\begin{itemize}
    \item[○] \textbf{高并发场景}：1000+并发任务的调度稳定性测试
    \item[○] \textbf{CPU热插拔}：动态CPU上下线时的调度器行为验证
    \item[○] \textbf{内存压力测试}：低内存环境下的调度器鲁棒性测试
    \item[○] \textbf{混合负载测试}：CPU密集型与I/O密集型任务混合场景的性能验证
\end{itemize}

\paragraph{社区化开发与推广}

为了推动Yat-CASched的进一步发展和应用，计划采用开源社区化的开发模式：

\begin{itemize}
    \item[★] \textbf{开源发布}：将项目发布到GitHub等平台，建立完整的文档和示例
    \item[★] \textbf{技术分享}：通过技术博客、会议演讲等方式分享设计理念和实现经验
    \item[★] \textbf{标准化推进}：参与Linux内核社区讨论，推动轻量级调度器的标准化
    \item[★] \textbf{产业应用探索}：与嵌入式系统厂商合作，推动在实际产品中的应用
\end{itemize}

\subsubsection{技术发展趋势适配}

\paragraph{新兴硬件架构的适配}

随着计算硬件的快速发展，调度器需要适配新的硬件特性：

\begin{itemize}
    \item[♦] \textbf{异构计算支持}：适配GPU、NPU等专用计算单元，实现异构任务调度
    \item[♦] \textbf{存储层次演进}：适配新兴存储技术（如持久内存）带来的缓存层次变化
    \item[♦] \textbf{多核心扩展}：为未来可能出现的大规模多核处理器设计可扩展的调度算法
\end{itemize}

\paragraph{人工智能技术的融合}

探索将机器学习技术应用到调度决策中：

\begin{itemize}
    \item[◇] \textbf{任务行为预测}：使用机器学习算法预测任务的运行时间和资源需求
    \item[◇] \textbf{自适应参数调优}：通过强化学习自动优化调度器参数
    \item[◇] \textbf{异常检测与恢复}：利用AI技术检测和处理调度异常情况
\end{itemize}

通过这些未来工作的逐步实现，Yat-CASched将从一个概念验证的原型，发展成为一个成熟、实用的轻量级调度器解决方案，真正实现"轻量化、低延迟、缓存感知"的设计目标，并在多个应用场景中发挥重要作用。
